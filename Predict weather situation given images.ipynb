{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "from model import Encoder, Decoder\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from os import listdir\n",
    "from seq2seq_parts import *\n",
    "from os.path import isfile, isdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from convlstm2d import ConvLSTMCell\n",
    "# from data_preprosess import get_clean_data\n",
    "from torch.optim import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data/train')\n",
    "\n",
    "images_paths = [os.path.join(data_dir, f) for f in listdir(data_dir) if isfile(os.path.join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_WIDTH = 256\n",
    "IMAGES_HEIGHT = 256\n",
    "IMAGES_DEPTH = 1\n",
    "\n",
    "TIME_STEMP = 6\n",
    "np.random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Training Data...\n",
      "Training data loading completed!\n",
      "we have 14566 Training Images Found.\n",
      "All data completely loaded!\n"
     ]
    }
   ],
   "source": [
    "features_list = np.zeros((len(images_paths), IMAGES_WIDTH, IMAGES_HEIGHT, IMAGES_DEPTH), dtype = np.uint8)\n",
    "\n",
    "def get_feature_images(paths, features_list):\n",
    "    for i, path in enumerate(paths):\n",
    "        image = cv2.imread(path, -1)\n",
    "        image = cv2.resize(image, (IMAGES_WIDTH, IMAGES_HEIGHT))\n",
    "        image = image.reshape(IMAGES_WIDTH, IMAGES_HEIGHT, IMAGES_DEPTH)\n",
    "        image = image.astype(np.uint8)\n",
    "        features_list[i] = image\n",
    "    return features_list\n",
    "\n",
    "    \n",
    "sys.stdout.flush()\n",
    "    \n",
    "print('Getting Training Data...')\n",
    "\n",
    "data = get_feature_images(images_paths, features_list)\n",
    "\n",
    "print('Training data loading completed!')\n",
    "\n",
    "\n",
    "print('we have {} Training Images Found.'.format(len(data)))\n",
    "\n",
    "print('All data completely loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprosessing complete!\n"
     ]
    }
   ],
   "source": [
    "X_train = data / 255\n",
    "print('Data Preprosessing complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_preprosess_data(data, frame, X_train):\n",
    "    length = len(data)\n",
    "    imgs = []\n",
    "    lbls = []\n",
    "    cnt_y = 0\n",
    "    for i in range(0, length, frame):\n",
    "        images = []\n",
    "        labels = []\n",
    "        cnt = 0\n",
    "        \n",
    "        for j in range(i, i + frame):\n",
    "            \n",
    "            if j < length:\n",
    "                images.append(X_train[j])\n",
    "            else:\n",
    "                images.append(X_train[cnt])\n",
    "                cnt += 1   \n",
    "            \n",
    "            le = j+1\n",
    "            if le < length:\n",
    "                try:\n",
    "                    labels.append(data[le])\n",
    "                except:\n",
    "                    labels.append(data[0])\n",
    "            else:\n",
    "                labels.append(data[cnt_y])\n",
    "                cnt_y +=1\n",
    "                \n",
    "        imgs.append(images)\n",
    "        lbls.append(labels)\n",
    "        \n",
    "    return imgs, lbls\n",
    "  \n",
    "train_X, train_Y = get_proper_preprosess_data(data, TIME_STEMP, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_X[:int(len(train_X) * 0.8)]\n",
    "Y_train = train_Y[:int(len(train_X) * 0.8)]\n",
    "\n",
    "val_X = train_X[int(len(train_X) * 0.91):]\n",
    "val_Y = train_Y[int(len(train_X) * 0.91):]\n",
    "\n",
    "test_X = train_X[int(len(train_X) * 0.9):]\n",
    "test_Y = train_Y[int(len(train_X) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    output_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [torch.from_numpy(features[start_i:end_i]).type(torch.FloatTensor), torch.from_numpy(labels[start_i:end_i]).type(torch.FloatTensor)]\n",
    "        output_batches.append(batch)\n",
    "        \n",
    "    return output_batches\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = batches(batch_size, X_train, Y_train)\n",
    "val_loader = batches(batch_size, val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop last batch\n",
    "last_train_batch = train_loader.pop(-1)\n",
    "last_validation_batch= val_loader.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_loader)\n",
    "random.shuffle(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "      \n",
    "    #initialize the encoder and decoder\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, features, targets, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        batch_size = targets.shape[1]\n",
    "        time = targets.shape[0]\n",
    "        \n",
    "        outputs = torch.FloatTensor(torch.zeros((time, batch_size, IMAGES_DEPTH, IMAGES_WIDTH, IMAGES_HEIGHT))).to(device)\n",
    "        \n",
    "        for t in range(time):\n",
    "            x1, x2, x3, x4, x5, output, states = self.encoder(features[t])\n",
    "            \n",
    "        decoder_hidden = states\n",
    "        layers = [x1, x2, x3, x4, x5]\n",
    "        output_encoder = output\n",
    "        \n",
    "        input = torch.FloatTensor(torch.zeros(output.shape)).to(device)\n",
    "        \n",
    "        for t in range(1, time):\n",
    "            decoder_output, decoder_hidden = self.decoder(layers[0], layers[1], layers[2], layers[3], layers[4], input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = (output_encoder if teacher_force else decoder_hidden[0])\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "def get_loss_per_epoch(model, feature, target, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "\n",
    "    time_stemp = feature.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    output = model(feature, target)\n",
    "\n",
    "    target_time_stemp = output.size(0)\n",
    "\n",
    "    #calculate the loss from a predicted sentence with the expected result\n",
    "    for t in range(target_time_stemp):\n",
    "        loss += criterion(output[t], target[t])\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / target_time_stemp\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, inputs, targets, num_iteration=10000):\n",
    "    model.train()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "#     training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n",
    "#                      for i in range(num_iteration)]\n",
    "\n",
    "    for iter in range(1, num_iteration+1):\n",
    "        input_pair = inputs[iter - 1]\n",
    "        targets_pair = targets[iter - 1]\n",
    "        input_tensor = input_pair.view(6, 1, 1, 256, 256).to(device)\n",
    "        target_tensor = targets_pair.view(6, 1, 1, 256, 256).to(device)\n",
    "\n",
    "        loss = get_loss_per_epoch(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            avarage_loss= total_loss_iterations / 5000\n",
    "            total_loss_iterations = 0\n",
    "            print('%d %.4f' % (iter, avarage_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), 'mytraining.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "decoder = Decoder()\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.train()\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-04\n",
    "\n",
    "optimizer = torch.optim.SGD(seq2seq.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "# optimizer = Adam(seq2seq.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 51/0 ...Training loss : 1455.4497\n",
      "Epochs : 51/1 ...Training loss : 1427.7880\n",
      "Epochs : 51/2 ...Training loss : 1427.6111\n",
      "Epochs : 51/3 ...Training loss : 1427.5617\n",
      "Epochs : 51/4 ...Training loss : 1427.4975\n",
      "Epochs : 51/5 ...Training loss : 1427.3347\n",
      "Epochs : 51/6 ...Training loss : 1427.1286\n",
      "Epochs : 51/7 ...Training loss : 1427.0143\n",
      "Epochs : 51/8 ...Training loss : 1426.8967\n",
      "Epochs : 51/9 ...Training loss : 1426.7987\n",
      "Epochs : 51/10 ...Training loss : 1426.7333\n",
      "Epochs : 51/11 ...Training loss : 1426.6647\n",
      "Epochs : 51/12 ...Training loss : 1426.5900\n",
      "Epochs : 51/13 ...Training loss : 1426.5119\n",
      "Epochs : 51/14 ...Training loss : 1426.4393\n",
      "Epochs : 51/15 ...Training loss : 1426.3755\n",
      "Epochs : 51/16 ...Training loss : 1426.3164\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        \n",
    "    total_loss_iterations = 0\n",
    "    for x, y in train_loader:\n",
    "        for i in range(len(x)):\n",
    "            tensor = x[i].view(6, 1, 1, 256, 256).cuda()\n",
    "            label = y[i].view(6, 1, 1, 256, 256).cuda()\n",
    "\n",
    "            loss = get_loss_per_epoch(seq2seq, tensor, label, optimizer, criterion)\n",
    "            total_loss_iterations += loss\n",
    "    else:\n",
    "        print('Epochs : 51/{}'.format(epoch), '...Training loss : {0:.4f}'.format(total_loss_iterations/14566))\n",
    "    torch.save(seq2seq.state_dict(), 'seq2seq_by_jimit_jayswal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
